{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW-3-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWzU9hqUomdU",
        "outputId": "a3105f6a-14d4-4bce-c6c0-2791c213d781"
      },
      "source": [
        "!pip3 install -q --upgrade nltk gensim bokeh pandas\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 23.9MB 111kB/s \n",
            "\u001b[K     |████████████████████████████████| 9.9MB 57.2MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-X7I7nc1gyS",
        "outputId": "f9205e8f-94e3-4680-8f6f-23107abac90c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoYjVExHd_OC"
      },
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvqrFUS6vVhh"
      },
      "source": [
        "## Запилим пословный машинный перевод!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CXcr-ypzGXg",
        "outputId": "44a8e1ea-c749-4ee5-be8d-8bb3c097ad0a"
      },
      "source": [
        "!wget -O ukr_rus.train.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1vAK0SWXUqei4zTimMvIhH3ufGPsbnC_O\"\n",
        "!wget -O ukr_rus.test.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1W9R2F8OeKHXruo2sicZ6FgBJUTJc8Us_\"\n",
        "!wget -O fairy_tale.txt -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1sq8zSroFeg_afw-60OmY8RATdu_T1tej\"\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1d7OXuil646jUeDS1JNhP9XWlZogv6rbu'})\n",
        "downloaded.GetContentFile('cc.ru.300.vec.zip')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1yAqwqgUHtMSfGS99WLGe5unSCyIXfIxi'})\n",
        "downloaded.GetContentFile('cc.uk.300.vec.zip')\n",
        "\n",
        "!unzip cc.ru.300.vec.zip\n",
        "!unzip cc.uk.300.vec.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cc.ru.300.vec.zip\n",
            "  inflating: cc.ru.300.vec           \n",
            "Archive:  cc.uk.300.vec.zip\n",
            "  inflating: cc.uk.300.vec           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RqUeOXxws8y"
      },
      "source": [
        "Напишем простенькую реализацию модели машинного перевода.\n",
        "\n",
        "Идея основана на статье [Word Translation Without Parallel Data](https://arxiv.org/pdf/1710.04087.pdf). У авторов в репозитории еще много интересного: [https://github.com/facebookresearch/MUSE](https://github.com/facebookresearch/MUSE).\n",
        "\n",
        "А мы будем переводить с украинского на русский.\n",
        "\n",
        "![](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/blue_cat_blue_whale.png)   \n",
        "*синій кіт* vs. *синій кит*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjPj9FTRry0U"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "ru_emb = KeyedVectors.load_word2vec_format(\"cc.ru.300.vec\")\n",
        "uk_emb = KeyedVectors.load_word2vec_format(\"cc.uk.300.vec\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGx4TXWFJ65"
      },
      "source": [
        "Посмотрим на пару серпень-август (являющихся переводом)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkHer36xyh4n",
        "outputId": "02ad50d4-7fd9-475c-88e9-e1d2a312a22e"
      },
      "source": [
        "ru_emb.most_similar([ru_emb[\"август\"]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('август', 1.0000001192092896),\n",
              " ('июль', 0.9383152723312378),\n",
              " ('сентябрь', 0.9240029454231262),\n",
              " ('июнь', 0.9222574830055237),\n",
              " ('октябрь', 0.9095539450645447),\n",
              " ('ноябрь', 0.8930036425590515),\n",
              " ('апрель', 0.8729087114334106),\n",
              " ('декабрь', 0.8652557730674744),\n",
              " ('март', 0.8545795679092407),\n",
              " ('февраль', 0.8401415944099426)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RSDixWvylEP",
        "outputId": "14b3d1bb-217d-4cec-fafa-4fc853df163b"
      },
      "source": [
        "uk_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('серпень', 0.9999998807907104),\n",
              " ('липень', 0.9096441268920898),\n",
              " ('вересень', 0.9016969203948975),\n",
              " ('червень', 0.8992518782615662),\n",
              " ('жовтень', 0.8810408115386963),\n",
              " ('листопад', 0.8787633180618286),\n",
              " ('квітень', 0.8592804670333862),\n",
              " ('грудень', 0.8586863279342651),\n",
              " ('травень', 0.840811014175415),\n",
              " ('лютий', 0.8256431221961975)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwmm3YQ1yl1U",
        "outputId": "f7ce37b2-b6af-4867-cbb6-a7cc54d9aada"
      },
      "source": [
        "ru_emb.most_similar([uk_emb[\"серпень\"]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Недопустимость', 0.24435284733772278),\n",
              " ('конструктивность', 0.23293082416057587),\n",
              " ('офор', 0.23256804049015045),\n",
              " ('deteydlya', 0.230317160487175),\n",
              " ('пресечении', 0.22632381319999695),\n",
              " ('одностороннего', 0.22608886659145355),\n",
              " ('подход', 0.2230587750673294),\n",
              " ('иболее', 0.22003726661205292),\n",
              " ('2015Александр', 0.21872766315937042),\n",
              " ('конструктивен', 0.21796567738056183)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAsW7oxszE_I"
      },
      "source": [
        "def load_word_pairs(filename):\n",
        "    uk_ru_pairs = []\n",
        "    uk_vectors = []\n",
        "    ru_vectors = []\n",
        "    with open(filename, \"r\", encoding='utf8') as inpf:\n",
        "        for line in inpf:\n",
        "            uk, ru = line.rstrip().split(\"\\t\")\n",
        "            if uk not in uk_emb or ru not in ru_emb:\n",
        "                continue\n",
        "            uk_ru_pairs.append((uk, ru))\n",
        "            uk_vectors.append(uk_emb[uk])\n",
        "            ru_vectors.append(ru_emb[ru])\n",
        "    return uk_ru_pairs, np.array(uk_vectors), np.array(ru_vectors)\n",
        "\n",
        "\n",
        "uk_ru_train, X_train, Y_train = load_word_pairs(\"ukr_rus.train.txt\")\n",
        "uk_ru_test, X_test, Y_test = load_word_pairs(\"ukr_rus.test.txt\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z6ts7DC0XmN"
      },
      "source": [
        "### Учим маппинг из одного пространства эмбеддингов в другое\n",
        "\n",
        "У нас есть пары слов, соответствующих друг другу, и их эмбеддинги. Найдем преобразование из одного пространства в другое, чтобы приблизить известные нам слова:\n",
        "\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F, \\text{где} ||*||_F - \\text{норма Фробениуса}$$\n",
        "\n",
        "Эта функция очень похожа на линейную регрессию (без биаса).\n",
        "\n",
        "**Задание** Реализуйте её - воспользуйтесь `LinearRegression` из sklearn с `fit_intercept=False`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fraTOQtu1YWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63be7961-4284-40f8-c5c5-302cc98e7b0b"
      },
      "source": [
        "# линейная регрессия на дефолтных настройках\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "mapping = LinearRegression(fit_intercept=False)\n",
        "mapping.fit(X_train,Y_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrzRk3ja1b_6"
      },
      "source": [
        "Проверим, куда перейдет `серпень`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quax6HnF1aON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e4df1f-a127-46f5-8918-285b2b834fc1"
      },
      "source": [
        "august = mapping.predict(uk_emb[\"серпень\"].reshape(1, -1))\n",
        "ru_emb.most_similar(august)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8541285991668701),\n",
              " ('июнь', 0.8411202430725098),\n",
              " ('март', 0.839699387550354),\n",
              " ('сентябрь', 0.835986852645874),\n",
              " ('февраль', 0.8329297304153442),\n",
              " ('октябрь', 0.8311845660209656),\n",
              " ('ноябрь', 0.8278923630714417),\n",
              " ('июль', 0.8234528303146362),\n",
              " ('август', 0.8120501637458801),\n",
              " ('декабрь', 0.8039003610610962)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih1GLNZt1nZX"
      },
      "source": [
        "Должно получиться, что в топе содержатся разные месяцы, но август не первый.\n",
        "\n",
        "Будем мерять percision top-k с k = 1, 5, 10.\n",
        "\n",
        "**Задание** Реализуйте следующую функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnmrLp9y2gNI"
      },
      "source": [
        "# немного исправил исходную заготовку функции, мне показалось так удобнее\n",
        "\n",
        "def precision(pairs, mapped_vectors, topn=1):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        pairs = list of right word pairs [(uk_word_0, ru_word_0), ...]\n",
        "        mapped_vectors = list of embeddings after mapping from source embedding space to destination embedding space\n",
        "        topn = the number of nearest neighbours in destination embedding space to choose from\n",
        "    :returns:\n",
        "        precision_val, float number, total number of words for those we can find right translation at top K.\n",
        "    \"\"\"\n",
        "    assert len(pairs) == len(mapped_vectors)\n",
        "    num_matches = 0\n",
        "    for (_, ru), ru_emb_pred in zip(pairs, mapped_vectors):\n",
        "        # список топ-н пар \"слово-дистанс\"\n",
        "        topn_similar = ru_emb.most_similar(ru_emb_pred.reshape(1,-1))[:topn]\n",
        "        topn_similar_words = [word for word, _ in topn_similar]\n",
        "        if ru in topn_similar_words:\n",
        "          num_matches += 1\n",
        "    precision_val = num_matches / len(pairs)\n",
        "    return precision_val"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1NIvhSH2olG"
      },
      "source": [
        "assert precision([(\"серпень\", \"август\")], august, topn=5) == 0.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=9) == 1.0\n",
        "assert precision([(\"серпень\", \"август\")], august, topn=10) == 1.0"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ml_w1Tl2r7Y"
      },
      "source": [
        "assert precision(uk_ru_test, X_test) == 0.0\n",
        "assert precision(uk_ru_test, Y_test) == 1.0"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9KQHMr2tx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb91c9c-e145-486b-f422-67abaa2e17d2"
      },
      "source": [
        "precision_top1 = precision(uk_ru_test, mapping.predict(X_test), 1)\n",
        "precision_top5 = precision(uk_ru_test, mapping.predict(X_test), 5)\n",
        "print('precision_top1', precision_top1)\n",
        "print('precision_top5', precision_top5)\n",
        "\n",
        "assert precision_top1 >= 0.635\n",
        "assert precision_top5 >= 0.813"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision_top1 0.6356589147286822\n",
            "precision_top5 0.813953488372093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNbDTP502urT"
      },
      "source": [
        "### Улучшаем маппинг\n",
        "\n",
        "Можно показать, что маппинг лучше строить ортогональным:\n",
        "$$W^*= \\arg\\min_W ||WX - Y||_F \\text{, где: } W^TW = I$$\n",
        "\n",
        "Искать его можно через SVD:\n",
        "$$X^TY=U\\Sigma V^T\\text{, singular value decompostion}$$\n",
        "\n",
        "$$W^*=UV^T$$\n",
        "\n",
        "**Задание** Реализуйте эту функцию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9de8XZ_F3v53"
      },
      "source": [
        "# все по формулам с помощью scipy\n",
        "\n",
        "from scipy.linalg import svd\n",
        "\n",
        "def learn_transform(X_train, Y_train):\n",
        "    \"\"\" \n",
        "    :returns: W* : float matrix[emb_dim x emb_dim] as defined in formulae above\n",
        "    \"\"\"\n",
        "    a = np.matmul(X_train.T, Y_train)\n",
        "    U, _, VT = svd(a)\n",
        "    return np.matmul(U, VT)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WeCadzN382y"
      },
      "source": [
        "W = learn_transform(X_train, Y_train)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6qaMb0E3-f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8469bcb-a796-4aa9-c3b2-7966f6ccb1a3"
      },
      "source": [
        "ru_emb.most_similar([np.matmul(uk_emb[\"серпень\"], W)])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('апрель', 0.8237908482551575),\n",
              " ('сентябрь', 0.8049713969230652),\n",
              " ('март', 0.802565336227417),\n",
              " ('июнь', 0.8021842837333679),\n",
              " ('октябрь', 0.800173819065094),\n",
              " ('ноябрь', 0.7934484481811523),\n",
              " ('февраль', 0.7914121150970459),\n",
              " ('июль', 0.7908109426498413),\n",
              " ('август', 0.7891018986701965),\n",
              " ('декабрь', 0.7686373591423035)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nn58crh4AH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e456cb-dda6-437d-df29-924b58d277ce"
      },
      "source": [
        "_p_1 = precision(uk_ru_test, np.matmul(X_test, W))\n",
        "_p_5 = precision(uk_ru_test, np.matmul(X_test, W), 5)\n",
        "\n",
        "print(_p_1)\n",
        "print(_p_5)\n",
        "\n",
        "assert _p_1 >= 0.653\n",
        "assert _p_5 >= 0.824"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6537467700258398\n",
            "0.8242894056847545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqgcYk-c4DE5"
      },
      "source": [
        "### Пишем переводчик"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwi70fP6FaAN"
      },
      "source": [
        "Реализуем простой пословный переводчик - для каждого слова будем искать его ближайшего соседа в общем пространстве эмбеддингов. Если слова нет в эмбеддингах - просто копируем его."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0etAHUks4JOr"
      },
      "source": [
        "with open(\"fairy_tale.txt\", \"r\") as f:\n",
        "    uk_sentences = [line.rstrip().lower() for line in f]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbSnYnrELmhm"
      },
      "source": [
        "# функция перевода одного слова\n",
        "\n",
        "# добавил обработку исключения - если исходного украинского слова нет в словаре\n",
        "# эмбедингов - то вернуть его в исходном виде, заключив в квадратные скобки\n",
        "\n",
        "def translate_word(uk_word):\n",
        "    try:\n",
        "        _uk_emb = uk_emb[uk_word]\n",
        "    except KeyError:\n",
        "        return f'[{uk_word}]'\n",
        "\n",
        "    ru_emb_pred = np.matmul(uk_emb[uk_word], W).reshape(1,-1)\n",
        "    ru_word, _ = ru_emb.most_similar(ru_emb_pred)[0]  # [0] - высший скор\n",
        "\n",
        "    return ru_word"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK_FJGmn4N7V"
      },
      "source": [
        "def translate(sentence):\n",
        "    \"\"\"\n",
        "    :args:\n",
        "        sentence - sentence in Ukrainian (str)\n",
        "    :returns:\n",
        "        translation - sentence in Russian (str)\n",
        "\n",
        "    * find ukrainian embedding for each word in sentence\n",
        "    * transform ukrainian embedding vector\n",
        "    * find nearest russian word and replace\n",
        "    \"\"\"\n",
        "    return ' '.join([translate_word(uk_word) for uk_word in sentence.split()])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LfPVY55IOphI",
        "outputId": "86f0ad5f-97d9-47c5-abe8-16cd539e9f98"
      },
      "source": [
        "translate(\".\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qHmecPOyOsOf",
        "outputId": "2036759e-2c1b-4a77-de57-08c787aed53e"
      },
      "source": [
        "translate(\"1 , 3\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1 , 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hYZ1I6sxUMn5",
        "outputId": "3ed4441b-c5b2-43c5-c1fc-590a8e83f290"
      },
      "source": [
        "translate(\"кіт зловив мишу\") "
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'кот поймал мышку'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47pbFyk4P6D"
      },
      "source": [
        "assert translate(\".\") == \".\"\n",
        "assert translate(\"1 , 3\") == \"1 , 3\"\n",
        "assert translate(\"кіт зловив мишу\") == \"кот поймал мышку\""
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAVWK7mE4RYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9fbf3e-cb9c-4143-91ae-be1a4513142c"
      },
      "source": [
        "for sentence in uk_sentences:\n",
        "    print(\"src: {}\\ndst: {}\\n\".format(sentence, translate(sentence)))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src: лисичка - сестричка і вовк - панібрат\n",
            "dst: лисичка – сестричка и волк – [панібрат]\n",
            "\n",
            "src: як була собі лисичка , да й пішла раз до однії баби добувать огню ; ввійшла у хату да й каже : \" добрий день тобі , бабусю !\n",
            "dst: как была себе лисичка , че и пошла раз к [однії] бабы [добувать] огня ; вошла во избу че и говорит : \" хороший день тебе , бабушку !\n",
            "\n",
            "src: дай мені огня \" .\n",
            "dst: дай мне огня \" .\n",
            "\n",
            "src: а баба тільки що вийняла із печі пирожок із маком , солодкий , да й положила , щоб він прохолов ; а лисичка се і підгледала , да тілько що баба нахилилась у піч , щоб достать огня , то лисичка зараз ухватила пирожок да і драла з хати , да , біжучи , весь мак із його виїла , а туда сміття наклала .\n",
            "dst: а бабка только что вынула со печи [пирожок] со маком , сладкий , че и согнула , чтобы он [прохолов] ; а лисичка ой и [підгледала] , че токмо что бабка качнулась во печь , чтобы [достать] огня , то лисичка сейчас [ухватила] [пирожок] че и деру со хаты , че , пробежать , весь мак со его [виїла] , а туда мусора наложила .\n",
            "\n",
            "src: прибігла на поле , аж там пасуть хлопці бичків .\n",
            "dst: прибежала по поле , аж там пасут парни бычков .\n",
            "\n",
            "src: вона і каже їм : \" ей , хлопці !\n",
            "dst: она и говорит им : \" ой , парни !\n",
            "\n",
            "src: проміняйте мені бичка - третячка за маковий пирожок \" .\n",
            "dst: [проміняйте] мне бычка – [третячка] за маковый [пирожок] \" .\n",
            "\n",
            "src: тії согласились ; так вона їм говорить : \" смотріть же , ви не їжте зараз сього пирожка , а тоді уже розломите , як я заведу бичка за могилку ; а то ви його ні за що не розломите \" .\n",
            "dst: ишо поглумиться ; так она им говорит : \" [смотріть] то , мы не ешьте сейчас сего [пирожка] , а тогда уже [розломите] , как мной [заведу] бычка за могилу ; а то мы его ни за что не [розломите] \" .\n",
            "\n",
            "src: бачите вже - лисичка таки собі була розумна , що хоть кого да обманить .\n",
            "dst: вижу уже – лисичка таки себе была умная , что хоть кого че [обманить] .\n",
            "\n",
            "src: тії хлопці так і зробили , а лисичка як зайшла за могилу , да зараз у ліс і повернула , щоб на дорозі не догнали ; прийшла у ліс да і зробила собі санки да й їде .\n",
            "dst: ишо парни так и сделали , а лисичка как зашла за могилу , че сейчас во лес и вернула , чтобы по дороге не погнали ; пришла во лес че и сделала себе санки че и едет .\n",
            "\n",
            "src: коли йде вовчик : \" здорова була , лисичко - сестричко ! \"\n",
            "dst: когда идет [вовчик] : \" здоровая была , [лисичко] – сестричка ! \"\n",
            "\n",
            "src: - \" здоров , вовчику - братику ! \"\n",
            "dst: – \" здоровье , [вовчику] – братику ! \"\n",
            "\n",
            "src: - \" де се ти узяла собі і бичка і санки ? \"\n",
            "dst: – \" куда ой ты взяла себе и бычка и санки ? \"\n",
            "\n",
            "src: - \" е !\n",
            "dst: – \" ьн !\n",
            "\n",
            "src: зробила \" .\n",
            "dst: сделала \" .\n",
            "\n",
            "src: - \" підвези ж і мене \" .\n",
            "dst: – \" [підвези] же и меня \" .\n",
            "\n",
            "src: - \" е , вовчику !\n",
            "dst: – \" ьн , [вовчику] !\n",
            "\n",
            "src: не можна \" .\n",
            "dst: не можно \" .\n",
            "\n",
            "src: - \" мені хоть одну ніжку \" .\n",
            "dst: – \" мне хоть одну ножку \" .\n",
            "\n",
            "src: - \" одну можна \" .\n",
            "dst: – \" одну можно \" .\n",
            "\n",
            "src: він і положив , да од'їхавши немного і просить , щоби іще одну положить .\n",
            "dst: он и положил , че [од'їхавши] конешно и просит , чтобы еще одну возмет .\n",
            "\n",
            "src: \" не можна , братику !\n",
            "dst: \" не можно , братику !\n",
            "\n",
            "src: боюсь , щоб ти саней не зламав \" .\n",
            "dst: боюсь , чтобы ты саней не сломал \" .\n",
            "\n",
            "src: - \" ні , сестричко , не бійся ! \"\n",
            "dst: – \" ни , сестричка , не бойся ! \"\n",
            "\n",
            "src: - да і положив другую ніжку .\n",
            "dst: – че и положил одну ножку .\n",
            "\n",
            "src: тілько що од'їхали , як щось і тріснуло .\n",
            "dst: токмо что [од'їхали] , как что-то и треснуло .\n",
            "\n",
            "src: \" бачиш , вовчику , уже і ламаєш санки \" .\n",
            "dst: \" видишь , [вовчику] , уже и [ламаєш] санки \" .\n",
            "\n",
            "src: - \" ні , лисичко !\n",
            "dst: – \" ни , [лисичко] !\n",
            "\n",
            "src: се у мене був орішок , так я розкусив \" .\n",
            "dst: ой во меня был [орішок] , так мной [розкусив] \" .\n",
            "\n",
            "src: да просить оп'ять , щоб і третю ногу положить ; лисичка і ту пустила , да тілько що оп'ять од'їхали , аж щось уже дужче тріснуло .\n",
            "dst: че просит [оп'ять] , чтобы и третью ногу возмет ; лисичка и ту пустила , че токмо что [оп'ять] [од'їхали] , аж что-то уже сильней треснуло .\n",
            "\n",
            "src: лисичка закричала : \" ох , лишечко !\n",
            "dst: лисичка закричала : \" ой , [лишечко] !\n",
            "\n",
            "src: ти ж мені , братику , зовсім зламаєш санки \" .\n",
            "dst: ты же мне , братику , совсем [зламаєш] санки \" .\n",
            "\n",
            "src: - \" ні , лисичко , се я орішок розкусив \" .\n",
            "dst: – \" ни , [лисичко] , ой мной [орішок] [розкусив] \" .\n",
            "\n",
            "src: - \" дай же і мені , бачиш який , що сам їж , а мені і не даєш \" .\n",
            "dst: – \" дай то и мне , видишь который , что сам ел , а мне и не даешь \" .\n",
            "\n",
            "src: - \" нема уже більше , а я б дав \" .\n",
            "dst: – \" нету уже больше , а мной бы дал \" .\n",
            "\n",
            "src: да і просить оп'ять , щоб пустила положить і послідню ногу .\n",
            "dst: че и просит [оп'ять] , чтобы пустила возмет и [послідню] ногу .\n",
            "\n",
            "src: лисичка і согласилась .\n",
            "dst: лисичка и [согласилась] .\n",
            "\n",
            "src: так він тілько що положив ногу , як санки зовсім розламались .\n",
            "dst: так он токмо что положил ногу , как санки совсем [розламались] .\n",
            "\n",
            "src: тоді вже лисичка так на його розсердилась , що і сама не знала щоб робила !\n",
            "dst: тогда уже лисичка так по его [розсердилась] , что и сама не знала чтобы делала !\n",
            "\n",
            "src: а як отошло серце , вона і каже : \" іди ж , ледащо !\n",
            "dst: а как [отошло] сердце , она и говорит : \" иди же , лодырь !\n",
            "\n",
            "src: да нарубай дерева , щоб нам оп'ять ізробить санки ; тільки рубавши кажи так : \" рубайся ж , дерево , і криве і пряме \" .\n",
            "dst: че [нарубай] деревья , чтобы нам [оп'ять] [ізробить] санки ; только [рубавши] говори так : \" [рубайся] же , дерево , и кривое и прямое \" .\n",
            "\n",
            "src: він і пішов да й каже усе : \" рубайся ж , дерево , усе пряме да пряме ! \"\n",
            "dst: он и пошел че и говорит всё : \" [рубайся] же , дерево , всё прямое че прямое ! \"\n",
            "\n",
            "src: нарубавши і приносить ; лисичка увидала , що дерево не таке , як їй нужно , оп'ять розсердилась .\n",
            "dst: [нарубавши] и приносит ; лисичка [увидала] , что дерево не такое , как им надо , [оп'ять] [розсердилась] .\n",
            "\n",
            "src: \" ти , - говорить , - не казав , видно , так , як я тобі веліла ! \"\n",
            "dst: \" ты , – говорит , – не говорил , видно , так , как мной тебе велела ! \"\n",
            "\n",
            "src: - \" ні , я усе теє казав , що ти мені казала \" .\n",
            "dst: – \" ни , мной всё Эх говорил , что ты мне говорила \" .\n",
            "\n",
            "src: - \" да чомусь не таке рубалось ?\n",
            "dst: – \" че почему-то не такое [рубалось] ?\n",
            "\n",
            "src: ну , сиди ж ти тут , а я сама піду нарубаю \" , - да і пішла у ліс .\n",
            "dst: ну , сиди же ты здесь , а мной сама пойду [нарубаю] \" , – че и пошла во лес .\n",
            "\n",
            "src: а вовк дивиться , що він сам остався ; узяв да проїв у бичка дірку да виїв усе в середині , а напускав туда горобців да ще соломою заткнув , поставив бичка , а сам і втік .\n",
            "dst: а волк смотрит , что он сам остался ; взял че [проїв] во бычка дыру че [виїв] всё во середине , а [напускав] туда воробьёв че ещe соломой заткнул , поставил бычка , а сам и сбежал .\n",
            "\n",
            "src: аж лисичка приходить , зробила санки да й сіла і стала поганять : \" гей , бичок - третячок ! \"\n",
            "dst: аж лисичка приходит , сделала санки че и присела и стала [поганять] : \" гей , бычок – [третячок] ! \"\n",
            "\n",
            "src: тілько він не везе .\n",
            "dst: токмо он не увозит .\n",
            "\n",
            "src: от вона встала , щоб поправить : може , що не так запряжено ; да , не хотячи , одоткнула солому , а оттуда так і сипнули горобці летіти .\n",
            "dst: из она встала , чтобы поправит : может , что не так [запряжено] ; че , не вздумал , [одоткнула] солому , а туды так и [сипнули] воробьи лететь .\n",
            "\n",
            "src: вона уже тоді побачила , що бичок неживий ; покинула його да й пішла .\n",
            "dst: она уже тогда увидела , что бычок неживой ; покинула его че и пошла .\n",
            "\n",
            "src: легла на дорозі , аж дивиться - їде мужик з рибою ; вона і притворилась , що здохла .\n",
            "dst: [легла] по дороге , аж смотрит – едет мужик со рыбой ; она и [притворилась] , что сдохла .\n",
            "\n",
            "src: от мужик і говорить : \" возьму я оцю лисицю , обдеру да хоть шапку собі зошью \" .\n",
            "dst: из мужик и говорит : \" возьму мной ихнюю лисицу , [обдеру] че хоть шапку себе [зошью] \" .\n",
            "\n",
            "src: узяв да і положив ззаді у воза .\n",
            "dst: взял че и положил взади во телега .\n",
            "\n",
            "src: вона замітила , що мужик не смотрить , стала ногами викидувать рибу з воза , а когда побачила , що навикидала уже багато , тоди потихесеньку і сама злізла ; сіла біля риби да і їсть собі , - коли біжить оп'ять той самий вовчик .\n",
            "dst: она заметила , что мужик не [смотрить] , стала ногами [викидувать] рыбу со телега , а .когда увидела , что [навикидала] уже много , тоды [потихесеньку] и сама слезла ; присела возле рыбы че и ест себе , – когда бежит [оп'ять] тот самый [вовчик] .\n",
            "\n",
            "src: побачивши , що вона їсть рибу , прибіг до їй да й каже : \" здорово була , лисичко - сестричко !\n",
            "dst: увидев , что она ест рыбу , прибежал к им че и говорит : \" здорово была , [лисичко] – сестричка !\n",
            "\n",
            "src: де се ти набрала стільки риби ? \"\n",
            "dst: куда ой ты набрала столько рыбы ? \"\n",
            "\n",
            "src: вона каже : \" наловила , вовчику - братику ! \"\n",
            "dst: она говорит : \" [наловила] , [вовчику] – братику ! \"\n",
            "\n",
            "src: а собі на думці : \" подожди , і я зроблю з тобою таку штуку , як і ти зо мною \" .\n",
            "dst: а себе по мнении : \" [подожди] , и мной сделаю со тобой такую штуку , как и ты За мной \" .\n",
            "\n",
            "src: - \" як же ти ловила ? \"\n",
            "dst: – \" как то ты ловила ? \"\n",
            "\n",
            "src: - \" так , вовчику , уложила хвостик в ополонку , вожу тихенько да й кажу ; ловися , рибка , мала і велика !\n",
            "dst: – \" так , [вовчику] , [уложила] хвостик во прорубь , вожу тихонько че и говорю ; [ловися] , рыбка , имела и большая !\n",
            "\n",
            "src: коли хочеш , то і ти піди , налови собі \" .\n",
            "dst: когда хочешь , то и ты пойди , [налови] себе \" .\n",
            "\n",
            "src: він побіг да зробив так , як казала лисичка .\n",
            "dst: он побежал че сделал так , как говорила лисичка .\n",
            "\n",
            "src: а лисичка стала за деревом да й дивиться ; коли у вовчика зовсім хвостик примерз , вона тоді побігла в село да й кричить : \" ідіть , люди , вбивайте вовка ! \"\n",
            "dst: а лисичка стала за деревом че и смотрит ; когда во [вовчика] совсем хвостик [примерз] , она тогда побежала во село че и кричит : \" идите , люди , убивайте волка ! \"\n",
            "\n",
            "src: люди набігли з кольями да і убили його .\n",
            "dst: люди полезли со [кольями] че и убили его .\n",
            "\n",
            "src: \n",
            "dst: \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5GrChTeFqIg"
      },
      "source": [
        "# Дополнительные материалы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwffxpbmFwDh"
      },
      "source": [
        "## Почитать\n",
        "### База:  \n",
        "[On word embeddings - Part 1, Sebastian Ruder](http://ruder.io/word-embeddings-1/)  \n",
        "[Deep Learning, NLP, and Representations, Christopher Olah](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)  \n",
        "\n",
        "### Как кластеризовать смыслы многозначных слов:  \n",
        "[Making Sense of Word Embeddings (2016), Pelevina et al](http://anthology.aclweb.org/W16-1620)    \n",
        "\n",
        "### Как оценивать эмбеддинги\n",
        "[Evaluation methods for unsupervised word embeddings (2015), T. Schnabel](http://www.aclweb.org/anthology/D15-1036)  \n",
        "[Intrinsic Evaluation of Word Vectors Fails to Predict Extrinsic Performance (2016), B. Chiu](https://www.aclweb.org/anthology/W/W16/W16-2501.pdf)  \n",
        "[Problems With Evaluation of Word Embeddings Using Word Similarity Tasks (2016), M. Faruqui](https://arxiv.org/pdf/1605.02276.pdf)  \n",
        "[Improving Reliability of Word Similarity Evaluation by Redesigning Annotation Task and Performance Measure (2016), Oded Avraham, Yoav Goldberg](https://arxiv.org/pdf/1611.03641.pdf)  \n",
        "[Evaluating Word Embeddings Using a Representative Suite of Practical Tasks (2016), N. Nayak](https://cs.stanford.edu/~angeli/papers/2016-acl-veceval.pdf)  \n",
        "\n",
        "\n",
        "## Посмотреть\n",
        "[Word Vector Representations: word2vec, Lecture 2, cs224n](https://www.youtube.com/watch?v=ERibwqs9p38)"
      ]
    }
  ]
}