{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект \"Предсказание отклика абонента на подключение услуги\"\n",
    "_Черненко А.Е._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка тренировочных и тестовых данных с наборами признаков по профилю потребления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск клиента Dask.\n",
    "\n",
    "Это предоствит панель мониторинга (Dashboard), которая полезна для получения информации о вычислениях.\n",
    "Ссылка на панель мониторинга в ячейке вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:61651</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>12.76 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:61651' processes=4 threads=4, memory=12.76 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве исходных данных доступна информация об отклике абонентов на предложение подключения одной из услуг __`data_train.csv`__, __`data_test.csv`__. Каждому пользователю может быть сделано несколько предложений в разное время, каждое из которых он может или принять, или отклонить.\n",
    "\n",
    "Отдельным набором данных представлен нормализованный анонимизированный набор признаков __`features.csv`__, характеризующий профиль потребления абонента. Эти данные привязаны к определенному времени, поскольку профиль абонента может меняться с течением времени.\n",
    "\n",
    "Итого, в качестве входных данных будут представлены:\n",
    "* __data_train.csv__: \n",
    "    * `id`,\n",
    "    * `vas_id`,\n",
    "    * `buy_time`,\n",
    "    * `target`;\n",
    "    \n",
    "    \n",
    "* __features.csv__: \n",
    "    * `id`, \n",
    "    * `<feature_list>`;\n",
    "\n",
    "и тестовый набор:\n",
    "* __data_test.csv__:\n",
    "    * `id`,\n",
    "    * `vas_id`,\n",
    "    * `buy_time`;\n",
    "\n",
    "где:\n",
    "* `target` - целевая переменная, где 1 означает подключение услуги, 0 - абонент не подключил услугу соответственно,\n",
    "* `buy_time` - время покупки, представлено в формате timestamp,\n",
    "* `id` - идентификатор абонента,\n",
    "* `vas_id` - подключаемая услуга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим исходные .csv-файлы в `dask.dataframe` и сразу переименуем столбцы индексов и `buy_time` для их различия между данными откликов и данными профилей потребления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мапер для переименования индексов и buy_time \n",
    "def mapper(name):\n",
    "    return {'Unnamed: 0': f'index_{name}', \n",
    "            'buy_time': f'buy_time_{name}'}\n",
    "\n",
    "\n",
    "dd_features = dd.read_csv('c://mfds/features.csv',sep='\\t').rename(columns=mapper('feat'))\n",
    "dd_train = dd.read_csv('data_train.csv').rename(columns=mapper('vas'))\n",
    "dd_test = dd.read_csv('data_test.csv').rename(columns=mapper('vas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наблюдений в \"data_train.csv\": 831653\n"
     ]
    }
   ],
   "source": [
    "LEN_TRAIN = len(dd_train.index)\n",
    "print(f'Наблюдений в \"data_train.csv\": {LEN_TRAIN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наблюдений в \"data_test.csv\": 71231\n"
     ]
    }
   ],
   "source": [
    "LEN_TEST = len(dd_test.index)\n",
    "print(f'Наблюдений в \"data_test.csv\": {LEN_TEST}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо все наблюдения из `data_train.csv` и `data_test.csv` дополнить соответствующими признаками из `features.csv`. \n",
    "\n",
    "Подробно рассмотрим алгоритм получения признаков из профиля потребления для тренировочной выборки, а затем повторим аналогичные дествия для тестовой выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем слияние тренировочной выборки `dd_train` и базы данных профилей потребления `dd_features`.\n",
    "Слияние проведем методом пересечения (`how='inner'`) по столбцу `id`. Данный способ подходит нам с допущением, что в `features.csv` имеются данные для всех `id`, с которыми мы будем работать в тренировочной и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = dd.merge(dd_train, dd_features, on=['id'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим результат слияния в виде `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = merged_train.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_vas</th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time_vas</th>\n",
       "      <th>target</th>\n",
       "      <th>index_feat</th>\n",
       "      <th>buy_time_feat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>4130548</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1544389200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8832</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>11.700029</td>\n",
       "      <td>17.790888</td>\n",
       "      <td>4.429214</td>\n",
       "      <td>...</td>\n",
       "      <td>-943.373846</td>\n",
       "      <td>-598.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-22.630448</td>\n",
       "      <td>-220.747724</td>\n",
       "      <td>-14.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842</td>\n",
       "      <td>540997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1541365200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11897</td>\n",
       "      <td>1545598800</td>\n",
       "      <td>-96.799971</td>\n",
       "      <td>-69.199112</td>\n",
       "      <td>-108.200786</td>\n",
       "      <td>...</td>\n",
       "      <td>-977.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-306.747724</td>\n",
       "      <td>-24.832889</td>\n",
       "      <td>0.305572</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>843</td>\n",
       "      <td>540997</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1542574800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11897</td>\n",
       "      <td>1545598800</td>\n",
       "      <td>-96.799971</td>\n",
       "      <td>-69.199112</td>\n",
       "      <td>-108.200786</td>\n",
       "      <td>...</td>\n",
       "      <td>-977.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-306.747724</td>\n",
       "      <td>-24.832889</td>\n",
       "      <td>0.305572</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_vas       id  vas_id  buy_time_vas  target  index_feat  \\\n",
       "0        140  4130548     2.0    1544389200     0.0        8832   \n",
       "1        842   540997     1.0    1541365200     0.0       11897   \n",
       "2        843   540997     4.0    1542574800     1.0       11897   \n",
       "\n",
       "   buy_time_feat          0          1           2  ...         243  \\\n",
       "0     1548018000  11.700029  17.790888    4.429214  ... -943.373846   \n",
       "1     1545598800 -96.799971 -69.199112 -108.200786  ... -977.373846   \n",
       "2     1545598800 -96.799971 -69.199112 -108.200786  ... -977.373846   \n",
       "\n",
       "          244        245        246         247        248       249  \\\n",
       "0 -598.770792 -25.996269 -22.630448 -220.747724 -14.832889 -0.694428   \n",
       "1 -613.770792 -25.996269 -37.630448 -306.747724 -24.832889  0.305572   \n",
       "2 -613.770792 -25.996269 -37.630448 -306.747724 -24.832889  0.305572   \n",
       "\n",
       "         250      251  252  \n",
       "0 -12.175933 -0.45614  1.0  \n",
       "1 -12.175933 -0.45614  0.0  \n",
       "2 -12.175933 -0.45614  0.0  \n",
       "\n",
       "[3 rows x 260 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдений в полученном датафрейме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860052"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что после слияния датафрейм имеет больше наблюдей, чем исходный. Это связано с тем, что для некоторых клиентов в данных профиля потребления имеются несколько записей, зафиксированных в разное время. Для таких случаев произошло дублирование некоторых наблюдений из `data_train.csv` с разными записями признков из `features.csv`. Избавляться от дубликатов будем с учетом актуальности по временни. То есть среди дубликатов будем оставлять только те наблдения, у которых разница между временными штампами отклика на услугу (`'buy_time_vas'`) и фиксации записи по признакам профиля потребления (`'buy_time_feat'`) минимальна. Введем новый столбец `'time_delta'`, который будет отражать указанную разницу во времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train['time_delta'] = abs(pd_train['buy_time_vas'] - pd_train['buy_time_feat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортируем наблюдения в порядке возрастания `'time_delta'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train.sort_values(['time_delta'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее удалим по порядку все дубликаты, оставляя лишь те, которые встречаются в датафрейме первыми (`keep='first'`). Благодаря сортировке и данному действию, среди дубликатов останутся лишь те наблюдения, которые имеют минимальное значение `time_delta`. Дублированными строками считаются те, которые имеют одинаковое значение `index_vas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train.drop_duplicates(['index_vas'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортируем датафрейм по возрастанию `index_vas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train.sort_values(['index_vas'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим нарушилась ли индексация `index_vas` путем сравнения со сброшенным на предыдущем этапе индеском датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd_train.index == pd_train['index_vas']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы совпадают, индексация не нарушена.\n",
    "\n",
    "Сравним количество наблюдений полученного датафрейма с `data_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наблюдений   в   исходном  \"data_train.csv\": 831653\n",
      "Наблюдений в новом тренирвоочном датафрейме: 831653\n"
     ]
    }
   ],
   "source": [
    "print(f'Наблюдений   в   исходном  \"data_train.csv\": {LEN_TRAIN}')\n",
    "print(f'Наблюдений в новом тренирвоочном датафрейме: {pd_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод: \n",
    "Индексация и количество наблюдений после извлечения и добавления признаков потребления __НЕ НАРУШЕНЫ__.\n",
    "\n",
    "Удалим лишние стобцы с индексами и признаком `buy_time` из `features.csv`. Признак `time_delta` оставим, так как он несет в себе информацию об актуальности признаков профиля потребления на момент отклика клиента на услугу. И сохраним датафрейм в `data_feat_train.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train.drop(['index_vas','index_feat', 'buy_time_feat'], axis=1).astype('float32').to_pickle('data_f32_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим алгоритм для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test = dd.merge(dd_test, dd_features, on=['id'], how='inner')\n",
    "pd_test = merged_test.compute()\n",
    "pd_test['time_delta'] = abs(pd_test['buy_time_vas'] - pd_test['buy_time_feat'])\n",
    "pd_test.sort_values(['time_delta'], inplace=True, ignore_index=True)\n",
    "pd_test.drop_duplicates(['index_vas'], keep='first', inplace=True)\n",
    "pd_test.sort_values(['index_vas'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексация в норме:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd_test.index == pd_test['index_vas']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество наблюдений сохранено:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наблюдений в исходном  \"data_test.csv\": 71231\n",
      "Наблюдений в новом тестовом датафрейме: 71231\n"
     ]
    }
   ],
   "source": [
    "print(f'Наблюдений в исходном  \"data_test.csv\": {LEN_TEST}')\n",
    "print(f'Наблюдений в новом тестовом датафрейме: {pd_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним датафрейм в `data_feat_test.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tornado.application - ERROR - Uncaught exception GET /status/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='127.0.0.1:8787', method='GET', uri='/status/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\aech\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tornado\\websocket.py\", line 546, in _run_callback\n",
      "    result = callback(*args, **kwargs)\n",
      "  File \"c:\\users\\aech\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\bokeh\\server\\views\\ws.py\", line 135, in open\n",
      "    raise ProtocolError(\"Token is expired.\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired.\n"
     ]
    }
   ],
   "source": [
    "pd_test.drop(['index_vas','index_feat'], axis=1).astype('float32').to_pickle('data_f32_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
