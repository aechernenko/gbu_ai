{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"project.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x5L-jvPpi8uB","colab_type":"text"},"source":["#### Черненко А.Е. \n","### Курсовой проект \n","# Image-to-Image Translation with Conditional Adversarial Networks\n","\n","\n","В курсовом проекте реализован способ преобразования схематичной карты в спутниковый снимок с использованием Conditional Adversarial Networks\n","\n","Проект создан на основе туториала \"Pix2Pix\" с сайта tensorflow, в котором данная сеть применялась для генерации изображений зданий на основе схематичных изображеий фасадов. https://www.tensorflow.org/tutorials/generative/pix2pix"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"e1_Y75QXJS6h"},"source":["## Импорты"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YfIk2es3hJEd","colab":{}},"source":["import tensorflow as tf\n","import os\n","from matplotlib import pyplot as plt\n","from IPython import display\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iYn4MdZnKCey"},"source":["## Загрузка датасета"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Kn-k8kTXuAlv","colab":{}},"source":["_URL = 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/maps.tar.gz'\n","\n","# Загружает файл с URL, если он не уже в кэше.\n","path_to_zip = tf.keras.utils.get_file('maps.tar.gz',\n","                                      origin=_URL,\n","                                      extract=True)\n","\n","# Путь к директории датасета\n","PATH = os.path.join(os.path.dirname(path_to_zip), 'maps/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2CbTEt448b4R","colab":{}},"source":["BUFFER_SIZE = 400  # размер буфера\n","BATCH_SIZE = 1  # размер пакета\n","IMG_WIDTH = 256  # ширина одного изображения\n","IMG_HEIGHT = 256  # высота одного изображения"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9LWiHkMbi8uO","colab_type":"text"},"source":["Исходные изображения в датасете имеют размер 1200 на 600. Эти изображения представляют собой склейки \"входного изображения\" (карты) и \"реального изображения\" (соответствующего карте реального спутникового снимка). Пример ниже."]},{"cell_type":"code","metadata":{"id":"C6ybjm7ai8uO","colab_type":"code","colab":{}},"source":["image = tf.io.read_file(PATH+'train/101.jpg')\n","image = tf.image.decode_jpeg(image)\n","image = tf.cast(image, tf.float32)\n","plt.imshow(image/255.)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VyMC_KSEi8uR","colab_type":"text"},"source":["Функция load преобразует входные изображения в два отдельных набора изображений: карты и реальные спутниковые снимки"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aO9ZAGH5K3SY","colab":{}},"source":["def load(image_file):\n","  image = tf.io.read_file(image_file)\n","  image = tf.image.decode_jpeg(image)\n","\n","  w = tf.shape(image)[1]\n","\n","  w = w // 2\n","  real_image = image[:, :w, :]\n","  input_image = image[:, w:, :]\n","\n","  input_image = tf.cast(input_image, tf.float32)\n","  real_image = tf.cast(real_image, tf.float32)\n","\n","  return input_image, real_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OIMfSh5Gi8uU","colab_type":"text"},"source":["Пример разделения исходного изображения"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4OLHMpsQ5aOv","colab":{}},"source":["inp, re = load(PATH+'train/101.jpg')\n","plt.figure()\n","plt.imshow(inp/255.0)\n","plt.figure()\n","plt.imshow(re/255.0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwi7ju7Ki8uY","colab_type":"text"},"source":["Функция resize изменяет размер изображений"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rwwYQpu9FzDu","colab":{}},"source":["def resize(input_image, real_image, height, width):\n","  input_image = tf.image.resize(input_image, [height, width],\n","                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","  real_image = tf.image.resize(real_image, [height, width],\n","                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","\n","  return input_image, real_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FG_TPgQti8ug","colab_type":"text"},"source":["Функция random_crop случайным образом обрезает изображения до размеров IMG_HEIGHT на IMG_WIDTH (у нас 256 на 256)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Yn3IwqhiIszt","colab":{}},"source":["def random_crop(input_image, real_image):\n","  stacked_image = tf.stack([input_image, real_image], axis=0)\n","  cropped_image = tf.image.random_crop(\n","      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n","\n","  return cropped_image[0], cropped_image[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F6SGmEC4i8uk","colab_type":"text"},"source":["Нормализация изображения к диапазону [-1, 1]"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"muhR2cgbLKWW","colab":{}},"source":["def normalize(input_image, real_image):\n","  input_image = (input_image / 127.5) - 1\n","  real_image = (real_image / 127.5) - 1\n","\n","  return input_image, real_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KmoR5g4Ii8un","colab_type":"text"},"source":["Функция random_jitter: \n","* изменение размера изображений на 286 х 286\n","* случайное обрезание изображений до размера 260 на 260\n","* с вероятностью \"50 на 50\" зеркальное отражение изображений слева направо"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fVQOjcPVLrUc","colab":{}},"source":["@tf.function()\n","def random_jitter(input_image, real_image):\n","  # resizing to 286 x 286 x 3\n","  input_image, real_image = resize(input_image, real_image, 286, 286)\n","\n","  # randomly cropping to 256 x 256 x 3\n","  input_image, real_image = random_crop(input_image, real_image)\n","\n","  if tf.random.uniform(()) > 0.5:\n","    # random mirroring\n","    input_image = tf.image.flip_left_right(input_image)\n","    real_image = tf.image.flip_left_right(real_image)\n","\n","  return input_image, real_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pY3SR7bAi8ur","colab_type":"text"},"source":["Пример"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n0OGdi6D92kM","colab":{}},"source":["plt.figure(figsize=(6, 6))\n","for i in range(0,4,2):\n","  rj_inp, rj_re = random_jitter(inp, re)\n","  plt.subplot(2, 2, i+1)\n","  plt.imshow(rj_inp/255.0)\n","  plt.subplot(2, 2, i+2)\n","  plt.imshow(rj_re/255.0)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-GOKC1hli8uu","colab_type":"text"},"source":["Функция подготовки тренировочных данных:\n","* загрузка\n","* случайный джиттер\n","* нормализация"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tyaP4hLJ8b4W","colab":{}},"source":["def load_image_train(image_file):\n","  input_image, real_image = load(image_file)\n","  input_image, real_image = random_jitter(input_image, real_image)\n","  input_image, real_image = normalize(input_image, real_image)\n","\n","  return input_image, real_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wYSEZWX3i8ux","colab_type":"text"},"source":["Функция подготовки тестовых данных:\n","* загрузка\n","* приведение к размеру IMG_HEIGHT на IMG_WIDTH\n","* нормализация"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VB3Z6D_zKSru","colab":{}},"source":["def load_image_test(image_file):\n","  input_image, real_image = load(image_file)\n","  input_image, real_image = resize(input_image, real_image,\n","                                   IMG_HEIGHT, IMG_WIDTH)\n","  input_image, real_image = normalize(input_image, real_image)\n","\n","  return input_image, real_image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PIGN6ouoQxt3"},"source":["## Входной пайплайн для подготовки тренировочного и тестового наборов данных"]},{"cell_type":"markdown","metadata":{"id":"S8XULM1yi8u1","colab_type":"text"},"source":["Тренировочные данные читаем из папки train, применяем к ним функцию подготовки load_image_train. Используем буфер фиксированного размера BUFFER_SIZE (у нас 400) для перемешивания элементов. И пакетизируем по BATCH_SIZE (у нас 1) элементов."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SQHmYSmk8b4b","colab":{}},"source":["train_dataset = tf.data.Dataset.list_files(PATH+'train/*.jpg')\n","train_dataset = train_dataset.map(load_image_train,\n","                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vzvo7Jp9i8u4","colab_type":"text"},"source":["Тестовые данные читаем из папки val, применяем к ним функцию подготовки load_image_test. И пакетизируем по BATCH_SIZE (у нас 1) элементов."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MS9J0yA58b4g","colab":{}},"source":["test_dataset = tf.data.Dataset.list_files(PATH+'val/*.jpg')\n","test_dataset = test_dataset.map(load_image_test)\n","test_dataset = test_dataset.batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"THY-sZMiQ4UV"},"source":["## Построение генератора\n","  * Архитектура генератора - модифицированная U-Net.\n","  * Каждый блок в кодере (Conv -> Batchnorm -> Leaky ReLU)\n","  * Каждый блок в декодере (Transposed Conv -> Batchnorm -> Dropout(применяется к первым 3 блокам) -> ReLU)\n","  * Между кодером и декодером есть пропуск соединений (как в U-Net)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tqqvWxlw8b4l","colab":{}},"source":["# каналов на выходе\n","OUTPUT_CHANNELS = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nAdLA_Fzi8vA","colab_type":"text"},"source":["Функция создания блока для нисходящего плеча. Параметры:\n","* количество ядер\n","* размер ядер\n","* применять / не применять BatchNormalization"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3R09ATE_SH9P","colab":{}},"source":["def downsample(filters, size, apply_batchnorm=True):\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  result = tf.keras.Sequential()\n","  result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n","                             kernel_initializer=initializer, use_bias=False))\n","\n","  if apply_batchnorm:\n","    result.add(tf.keras.layers.BatchNormalization())\n","\n","  result.add(tf.keras.layers.LeakyReLU())\n","\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mUoG5o2Njdr9","colab_type":"text"},"source":["Функция создания блока для восходящего плеча. Параметры:\n","* количество ядер\n","* размер ядер\n","* применять / не применять дропаут половины связей"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nhgDsHClSQzP","colab":{}},"source":["def upsample(filters, size, apply_dropout=False):\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  result = tf.keras.Sequential()\n","  result.add(\n","    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer=initializer,\n","                                    use_bias=False))\n","\n","  result.add(tf.keras.layers.BatchNormalization())\n","\n","  if apply_dropout:\n","      result.add(tf.keras.layers.Dropout(0.5))\n","\n","  result.add(tf.keras.layers.ReLU())\n","\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zp5nsVYGjh18","colab_type":"text"},"source":["Функция построения генератора"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lFPI4Nu-8b4q","colab":{}},"source":["def Generator():\n","  # входной слой\n","  inputs = tf.keras.layers.Input(shape=[256,256,3])\n","\n","  # слои нисходящего плеча\n","  down_stack = [\n","    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n","    downsample(128, 4), # (bs, 64, 64, 128)\n","    downsample(256, 4), # (bs, 32, 32, 256)\n","    downsample(512, 4), # (bs, 16, 16, 512)\n","    downsample(512, 4), # (bs, 8, 8, 512)\n","    downsample(512, 4), # (bs, 4, 4, 512)\n","    downsample(512, 4), # (bs, 2, 2, 512)\n","    downsample(512, 4), # (bs, 1, 1, 512)\n","  ]\n","\n","  # слои восходящего плеча\n","  up_stack = [\n","    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n","    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n","    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n","    upsample(512, 4), # (bs, 16, 16, 1024)\n","    upsample(256, 4), # (bs, 32, 32, 512)\n","    upsample(128, 4), # (bs, 64, 64, 256)\n","    upsample(64, 4), # (bs, 128, 128, 128)\n","  ]\n","\n","  # выходной слой\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n","                                         strides=2,\n","                                         padding='same',\n","                                         kernel_initializer=initializer,\n","                                         activation='tanh') # (bs, 256, 256, 3)\n","\n","  #-----------------------------------------------------------------------------\n","  # СВЯЗЫВНИЕ СЛОЕВ:\n","   \n","  # сначала входной слой\n","  x = inputs\n","\n","  # связывание слоев по нисходящему плечу\n","  skips = []\n","  for down in down_stack:\n","    x = down(x)\n","    skips.append(x)\n","\n","  skips = reversed(skips[:-1])  # список выходов с пропущенными соединениями (для конкатенации)\n","\n","  # Связывание слоев по восходящему плечу с восстановлением пропущенных соединений (где конкатенация)\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    x = tf.keras.layers.Concatenate()([x, skip])\n","  \n","  # выходной слой\n","  x = last(x)\n","\n","  return tf.keras.Model(inputs=inputs, outputs=x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"86TTQCdDi8vQ","colab_type":"text"},"source":["Посмотрим на схему генератора"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dIbRPFzjmV85","colab":{}},"source":["generator = Generator()\n","tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dpDPEQXIAiQO"},"source":["### Функция потерь генератора\n","* функция потерь - сигмоидная кросс-энтропия генерируемых изображений и подобных по размерности единичных тензоров.\n","* Так же включена функция потерь L1, являющаяся MAE (средняя абсолютная ошибка) между генерируемым изображением и целевым изображением. \n","* Все это позволяет сгенерированному изображению стать структурно похожим на целевое изображение.\n","* Формула для расчета суммарных потерь генератора = gan_loss + LAMBDA * l1_loss, где LAMBDA = 100. Это значение было определено авторами оригинальной статьи (https://arxiv.org/pdf/1611.07004.pdf)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cyhxTuvJyIHV","colab":{}},"source":["LAMBDA = 100\n","loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"90BIcCKcDMxz","colab":{}},"source":["def generator_loss(disc_generated_output, gen_output, target):\n","  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n","\n","  # MAE\n","  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n","\n","  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n","\n","  return total_gen_loss, gan_loss, l1_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vuv0rpaVi8vZ","colab_type":"text"},"source":["Процедура обучения для генератора"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TlB-XMY5Awj9"},"source":["![Generator Update Image](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/gen.png?raw=1)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZTKZfoaoEF22"},"source":["## Построение дискриминатора\n","  * Архитектура дискриминатора - PatchGAN.\n","  * Каждый блок дискриминатора - (Conv -> BatchNorm -> Leaky ReLU)\n","  * размерность выхода (batch_size, 30, 30, 1)\n","  * PatchGAN классифицирует каждую NxN часть изображения на предмет True/Fake\n","  * Дискриминатор принимает 2 входа.\n","    * Входное изображение и целевое изоражение, которое должно классифицироваться как True.\n","    * Входное изображение и сгенерированное изображение (выход генератора), которое должно классифицироваться как Fake.\n","    * Эти два хода объединены с помощью (`tf.concat([inp, tar], axis=-1)`)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ll6aNeQx8b4v","colab":{}},"source":["def Discriminator():\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  # Входной слой 1\n","  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n","  # Входной слой 2\n","  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n","\n","  # Объединенный входной слой\n","  x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n","\n","  # Добавляем сверточные слои\n","  down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n","  down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n","  down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n","\n","  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n","  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n","                                kernel_initializer=initializer,\n","                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n","\n","  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n","\n","  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n","\n","  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n","\n","  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n","                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n","\n","  return tf.keras.Model(inputs=[inp, tar], outputs=last)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"InQYdGQ7i8ve","colab_type":"text"},"source":["Посмотрим схему дисриминатора"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YHoUui4om-Ev","colab":{}},"source":["discriminator = Discriminator()\n","tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AOqg1dhUAWoD"},"source":["Функция потерь дискриминатора\n","\n","\n","  * Функция потерь дискриминатора имеет 2 входа; **реальные изображения, сгенерированные изображения**\n","  * real_loss сигмоидная кросс энтропия **реального изображения** и **единичного тензора**\n","  * generated_loss сигмоидная кросс энтропия **сгенерированного изоражения** and an **нулевого тензора**\n","  * В конечном итоге total_loss это сумма real_loss и the generated_loss\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wkMNfBWlT-PV","colab":{}},"source":["def discriminator_loss(disc_real_output, disc_generated_output):\n","  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n","\n","  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n","\n","  total_disc_loss = real_loss + generated_loss\n","\n","  return total_disc_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-ede4p2YELFa"},"source":["Процедура обучения для дискриминатора"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IS9sHa-1BoAF"},"source":["![Discriminator Update Image](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/images/dis.png?raw=1)\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0FMYgY_mPfTi"},"source":["## Оптимизаторы и Checkpoint-saver"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lbHFNexF0x6O","colab":{}},"source":["generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WJnftd5sQsv6","colab":{}},"source":["checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                                 discriminator_optimizer=discriminator_optimizer,\n","                                 generator=generator,\n","                                 discriminator=discriminator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Rw1fkAczTQYh"},"source":["## Генерация изображений\n","\n","* Изображения из тестового набора передаются в генератор.\n","* Затем генератор преоразует входное изоражение в выходное.\n","* На последнем шаге оторажается прогноз"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RmdVsmvhPxyy","colab":{}},"source":["def generate_images(model, test_input, tar):\n","  prediction = model(test_input, training=True)\n","  plt.figure(figsize=(15,15))\n","\n","  display_list = [test_input[0], tar[0], prediction[0]]\n","  title = ['Входное изображение', 'Реальное изображение', 'Предсказанное изображение']\n","\n","  for i in range(3):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n","    # getting the pixel values between [0, 1] to plot it.\n","    plt.imshow(display_list[i] * 0.5 + 0.5)\n","    plt.axis('off')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NLKOG55MErD0"},"source":["## Обучение\n","\n","* Для каждого примера входной сигнал генерирует выходной сигнал.\n","* Дискриминатор получает input_image и сгенерированное изображение в качестве первого входного сигнала. Второй вход - это input_image и target_image.\n","* Далее расчитываются потери генератора и дискриминатора.\n","* Затем вычисляются градиенты потерь по отношению как к генератору, так и к дискриминантным переменным(входным сигналам) и применяются к оптимизатору."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NS2GWywBbAWo","colab":{}},"source":["EPOCHS = 150"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KBKUV2sKXDbY","colab":{}},"source":["@tf.function\n","def train_step(input_image, target, epoch):\n","  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","    gen_output = generator(input_image, training=True)\n","\n","    disc_real_output = discriminator([input_image, target], training=True)\n","    disc_generated_output = discriminator([input_image, gen_output], training=True)\n","\n","    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n","    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n","\n","  generator_gradients = gen_tape.gradient(gen_total_loss,\n","                                          generator.trainable_variables)\n","  discriminator_gradients = disc_tape.gradient(disc_loss,\n","                                               discriminator.trainable_variables)\n","\n","  generator_optimizer.apply_gradients(zip(generator_gradients,\n","                                          generator.trainable_variables))\n","  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n","                                              discriminator.trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hx7s-vBHFKdh"},"source":["Фактический цикл обучения:\n","\n","* Перебор числа эпох.\n","* В каждую эпоху запускается \"generate_images\", чтобы показать прогресс.\n","* В каждой эпохе обрабатывается набор обучающих данных, выводится очередная точка для каждого примера.\n","* Чекпоинт сохраняется каждые 20 эпох."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2M7LmLtGEMQJ","colab":{}},"source":["def fit(train_ds, epochs, test_ds):\n","  for epoch in range(epochs):\n","    start = time.time()\n","\n","    display.clear_output(wait=True)\n","\n","    for example_input, example_target in test_ds.take(1):\n","      generate_images(generator, example_input, example_target)\n","    print(\"Epoch: \", epoch)\n","\n","    # Train\n","    for n, (input_image, target) in train_ds.enumerate():\n","      print('.', end='')\n","      if (n+1) % 100 == 0:\n","        print()\n","      train_step(input_image, target, epoch)\n","    print()\n","\n","    # saving (checkpoint) the model every 20 epochs\n","    if (epoch + 1) % 20 == 0:\n","      checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n","                                                        time.time()-start))\n","  checkpoint.save(file_prefix = checkpoint_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Pe0-8Bzg22ox"},"source":["## Запуск тренирововчного цикла"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"a1zZmKmvOH85","colab":{}},"source":["fit(train_dataset, EPOCHS, test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kz80bY3aQ1VZ"},"source":["## Восстановление последнего чекпойнта"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HSSm4kfvJiqv","colab":{}},"source":["!ls {checkpoint_dir}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4t4x69adQ5xb","colab":{}},"source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1RGysMU_BZhx"},"source":["## Генерация на тестовых данных"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KUgSnmy2nqSP","colab":{}},"source":["# Run the trained model on a few examples from the test dataset\n","for inp, tar in test_dataset.take(5):\n","  generate_images(generator, inp, tar)"],"execution_count":null,"outputs":[]}]}