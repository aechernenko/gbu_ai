{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhwkeWtb1O0w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeKFn2yb1To4"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450,\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, \n",
    "               1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "yXSj4nbxHsFd",
    "outputId": "8d102d54-94bf-4acc-d5b8-d60da152b953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00,\n",
       "        1.00e+00, 1.00e+00, 1.00e+00, 1.00e+00],\n",
       "       [1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00, 3.00e+00, 0.00e+00,\n",
       "        5.00e+00, 1.00e+01, 1.00e+00, 2.00e+00],\n",
       "       [5.00e+02, 7.00e+02, 7.50e+02, 6.00e+02, 1.45e+03, 8.00e+02,\n",
       "        1.50e+03, 2.00e+03, 4.50e+02, 1.00e+03],\n",
       "       [1.00e+00, 1.00e+00, 2.00e+00, 1.00e+00, 2.00e+00, 1.00e+00,\n",
       "        3.00e+00, 3.00e+00, 1.00e+00, 2.00e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QU0A16vZHugZ",
    "outputId": "71d74b95-77f4-41a7-e339-c9e7b2004e4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-aO1NTxOUfo"
   },
   "outputs": [],
   "source": [
    "def calc_std_feat(x):\n",
    "  res = (x - x.mean()) / x.std()\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8EL0iGJOVpe"
   },
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])\n",
    "#X_st[1, :] = calc_std_feat(X[2, :])\n",
    "#X_st[3, :] = calc_std_feat(X[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "gviMxz7EOuI3",
    "outputId": "af9a2576-f4d7-41d7-e216-46e0a068cfad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  2.        ,  1.        ,  3.        ,\n",
       "         0.        ,  5.        , 10.        ,  1.        ,  2.        ],\n",
       "       [-0.97958969, -0.56713087, -0.46401617, -0.77336028,  0.97958969,\n",
       "        -0.36090146,  1.08270439,  2.11385144, -1.08270439,  0.05155735],\n",
       "       [ 1.        ,  1.        ,  2.        ,  1.        ,  2.        ,\n",
       "         1.        ,  3.        ,  3.        ,  1.        ,  2.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMR5pOA38dDw"
   },
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "  err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "  return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEF9rWPNDnss"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  res = 1 / (1 + np.exp(-z))\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6TH-mkPItb6"
   },
   "outputs": [],
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtgUN3LW-UIq"
   },
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "        if i % (iterations / 10) == 0:\n",
    "            print(i, W, err)\n",
    "    print('final:', i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "oqX7loklBmYZ",
    "outputId": "f4849295-1f14-40d8-c8f2-d1b002e130c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [ 0.49282748 -0.15007528  0.64748973  1.51727915] 1.2014814214705334\n",
      "200 [ 0.48896219 -0.16184918  0.64728128  1.51155738] 1.1828456288538924\n",
      "300 [ 0.48511874 -0.17358386  0.64706349  1.50586552] 1.1643525542846556\n",
      "400 [ 0.4812976  -0.18527698  0.64683669  1.50020462] 1.1460086359433084\n",
      "500 [ 0.47749927 -0.19692597  0.64660127  1.4945758 ] 1.127820879406358\n",
      "600 [ 0.47372426 -0.20852799  0.6463577   1.48898028] 1.109796908143704\n",
      "700 [ 0.46997312 -0.22007992  0.6461065   1.48341934] 1.0919450148769096\n",
      "800 [ 0.46624642 -0.23157833  0.64584825  1.47789438] 1.074274212586137\n",
      "900 [ 0.46254476 -0.24301946  0.64558365  1.4724069 ] 1.0567942835649755\n",
      "1000 [ 0.45886878 -0.25439917  0.64531344  1.46695851] 1.0395158244739489\n",
      "final: 1000 [ 0.45886878 -0.25439917  0.64531344  1.46695851] 1.0395158244739489\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=1000, alpha=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mbwxo9NqbLJy"
   },
   "source": [
    "* 1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.  \n",
    "* 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n",
    "* 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n",
    "* 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).\n",
    "* 5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.\n",
    "* 6. Могла ли модель переобучиться? Почему?\n",
    "* 7*. Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наблюдения, у которых y_pred равным нулю или единице, удаляются и для y, и для y_pred\n",
    "def calc_logloss_2(y, y_pred):\n",
    "    mask = (y_pred != 0) & (y_pred != 1)\n",
    "    y, y_pred = y[mask], y_pred[mask]\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вводится очень маленькое смещение eps, которое исправляет нули и единицы\n",
    "def calc_logloss(y, y_pred, eps=1e-6):    \n",
    "    y_pred[y_pred == 0] += eps\n",
    "    y_pred[y_pred == 1] -= eps\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [-218.44881792  -27.84590461  -60.81462963  189.88316294] 0.2390512648230097\n",
      "2000 [-234.54499885  -25.10350543  -66.53780997  191.06846094] 0.00645743193984973\n",
      "3000 [-237.46011286  -23.25046349  -68.07982048  190.5404232 ] 0.0059711794012337945\n",
      "4000 [-240.16643948  -21.53022615  -69.51130773  190.05037845] 0.005552161444326035\n",
      "5000 [-242.69156979  -19.9252465   -70.84688238  189.59330321] 0.005187434996927515\n",
      "6000 [-245.05764095  -18.42214777  -72.0986911   189.16542187] 0.0048672974595573215\n",
      "7000 [-247.09692926  -17.39828143  -73.24254075  189.002233  ] 0.004640831092655286\n",
      "8000 [-248.4974914   -17.32525064  -73.79532264  189.76128212] 0.004544023347209528\n",
      "9000 [-249.76487218  -17.39591521  -74.18654692  190.69600471] 0.004456261953990788\n",
      "10000 [-251.00269181  -17.4726893   -74.56218327  191.62325442] 0.004371807600068995\n",
      "final: 10000 [-251.00269181  -17.4726893   -74.56218327  191.62325442] 0.004371807600068995\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=10000, alpha=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(w, X):  \n",
    "    return sigmoid(np.dot(w, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.16305490e-02, 9.73522623e-16, 1.00000000e+00, 4.63933092e-09,\n",
       "       9.98871124e-01, 7.91642841e-15, 1.00000000e+00, 2.08951457e-04,\n",
       "       9.79701019e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = calc_pred_proba(W,X_st)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(w, X, threshold=0.5):\n",
    "    y_predicted = np.zeros((1, X.shape[1]))\n",
    "    w = w.reshape(X.shape[0], 1)    \n",
    "    A = sigmoid(np.dot(w.T, X))\n",
    "    for i in range(A.shape[1]):\n",
    "        if (A[:,i] > threshold): \n",
    "            y_predicted[:, i] = 1\n",
    "        elif (A[:,i] <= threshold):\n",
    "            y_predicted[:, i] = 0    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(W,X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y, y_pred, printed=False):\n",
    "    cm = np.zeros(4).reshape((2,2))\n",
    "    for i in (0,1):\n",
    "        for j in (0,1):\n",
    "            a = (y_pred==i)&(y==j)\n",
    "            cm[i,j] = a[a==True].shape[0]\n",
    "    \n",
    "    if printed:\n",
    "        print('        \\t y=0\\t y=1')\n",
    "        print('y_pred=0\\t',cm[0,0],'\\t',cm[0,1])\n",
    "        print('y_pred=1\\t',cm[1,0],'\\t',cm[1,1])\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        \t y=0\t y=1\n",
      "y_pred=0\t 5.0 \t 0.0\n",
      "y_pred=1\t 0.0 \t 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5., 0.],\n",
       "       [0., 5.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, y_pred, printed=True)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = cm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (TN+TP)/cm.sum()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = TP/(TP+FP)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = TP/(TP+FN)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = 2*precision*recall/(precision+recall)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_\"При большой размерности пространства или малой длине выборки возможно переобучение. При этом резко возрастает норма вектора весов (появляются большие по абсолютной величине положительные и отрицательные веса), классификация становится неустойчивой (малые изменения обучающей выборки, начального приближения, порядка предъявления объектов или параметров алгоритма η, λ могут сильно изменить результирующий вектор весов), увеличивается вероятность ошибочной классификации новых объектов.\"_\n",
    "\n",
    "_\"Ранний останов. Слишком глубокая оптимизация может приводить к переобучению. Узкий глобальный минимум функционала Q(w) менее предпочтителен, чем более пологий и устойчивый локальный минимум. Для предотвращения попадания в такие «расщелины» применяется техника раннего останова (early stopping). По ходу итераций вычисляется какой-нибудь внешний критерий , и если он начинает возрастать, процесс настройки прекращается.\"_\n",
    "\n",
    "___(с) Лекции по линейным алгоритмам классификации, К. В. Воронцов___\n",
    "\n",
    "\n",
    "Видно, что наши веса имеют большие значения.\n",
    "\n",
    "* w0 248.93903554\n",
    "* w1 -17.34418622\n",
    "* w2 -73.93669082\n",
    "* w3 190.07604743\n",
    "\n",
    "Очевидно, модель переобучена.\n",
    "\n",
    "Потому что: 1) В нашем случае выборка имеет малую длину. 2) Проводилась глубокая оптимизация\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7*. Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чуть позже доделаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson3_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
